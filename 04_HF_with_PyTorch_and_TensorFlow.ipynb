{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1c6faa-2048-44d6-b5cc-3631f99b4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification ,pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f47654c-4e15-4264-88fc-5b9013b494a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"xlnet-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "sentence = \"I am so excited to be learning about large language models\"\n",
    "input_ids = tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a861522-e807-472f-bda7-1d7a28cc8fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [35, 569, 102, 5564, 22, 39, 1899, 75, 392, 1243, 2626, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0dd04f-aa1a-4e05-a591-40c1bc40b16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356836e80b7f4f788d0dde6761a40778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\pyspark\\nlp_course\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aniket\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cf78c7c8fe4d988c52b25bc3e9333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212e39b82f2040f2822dc8aa2c926a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf902a45-5d04-4c83-92b5-23886ee6dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2572, 2061, 7568, 2000, 2022, 4083, 2055, 2312, 2653, 4275,\n",
      "          102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "input_ids_pt = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(input_ids_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d3ea82-3d0d-414a-8325-1e589c605453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9a9f6b29a64adcb8e24325076ef02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "704562d8-aeba-476d-b2c6-2aa5ec72c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = classification_model(**input_ids_pt).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "classification_model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f8a4e-2698-42ba-a3db-940158c51c1c",
   "metadata": {},
   "source": [
    "## Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37beee51-7443-4593-a9db-89ee047e1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'my_saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8828358-1643-4794-8141-a6fac25f323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_saved_models\\\\tokenizer_config.json',\n",
       " 'my_saved_models\\\\special_tokens_map.json',\n",
       " 'my_saved_models\\\\vocab.txt',\n",
       " 'my_saved_models\\\\added_tokens.json',\n",
       " 'my_saved_models\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1140fe0a-076c-4f95-b3a6-95993859012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.save_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c184c45c-b2bf-4967-8712-03d4a265b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer = AutoTokenizer.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6245203a-87bf-4cf2-8ba5-41dd734e311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = AutoModelForSequenceClassification.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae9b32-3bdd-4567-9271-e279c4a9942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
