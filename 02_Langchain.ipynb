{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57feeb12-0935-467d-a7d8-977975a4f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.memory import ConversationBufferMemory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from configs import API_KEY, DEFAULT_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2236fb06-feaf-4acc-942d-53744f06d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://365datascience.com/upcoming-courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7714147b-a407-4db8-bc5b-e034b257dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ca5834b-2522-4665-8823-e52defffe33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6397c7c3-be1e-4bc2-a8e4-902dae12e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(raw_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07ca55b8-f18a-47d2-a900-86f8262377ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26efe722-839b-48da-96e4-17699b186382",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376b6085-4514-4a2c-aef1-642b8ce2d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatOpenAI(openai_api_key = API_KEY, model=\"gpt-4o-mini\")\n",
    "store = {}\n",
    "\n",
    "def get_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain = RunnableWithMessageHistory(llm, get_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673a701-fb68-4a5b-9353-46ba36f07f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e94926d-3f05-44f8-b181-d94de79e8c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from URL...\n",
      "Splitting documents...\n",
      "Building vector store...\n",
      "Creating RAG chain...\n",
      "RAG chatbot ready. Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is the next course to be uploaded on 365DataScience platform ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The provided context does not specify the next course to be uploaded on the 365 Data Science platform.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is 365dataSciencePLatform?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: 365 Data Science is an online platform offering structured data science courses and certification programs. It provides training on in-demand tools like Python, SQL, and R, covering topics such as data analysis, machine learning, AI, data visualization, and more. The platform supports various career tracks including Data Scientist, Data Analyst, AI Engineer, and others, with courses designed for different skill levels from beginner to advanced.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    113\u001b[39m     chat_loop(rag_chain)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating RAG chain...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m rag_chain = create_rag_chain(vectorstore)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mchat_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_chain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mchat_loop\u001b[39m\u001b[34m(rag_chain)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRAG chatbot ready. Type \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to quit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     question = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m question.lower() \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\pyspark\\nlp_course\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\pyspark\\nlp_course\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# 1. Config\n",
    "# OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "\n",
    "SOURCE_URL = \"https://365datascience.com/upcoming-courses\"  # example: replace with your URL\n",
    "PERSIST_DIR = None #\"./chroma_db\"  # or None if you don't want persistence\n",
    "\n",
    "# 2. Load docs from the web\n",
    "def load_docs_from_url(url: str) -> List[Document]:\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer()  # customize this for more precise HTML selection\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "# 3. Split docs into chunks\n",
    "def split_docs(docs: List[Document]) -> List[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "# 4. Build or load vector store\n",
    "def build_vectorstore(chunks: List[Document]) -> Chroma:\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=PERSIST_DIR,\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "# 5. Create RAG chain\n",
    "def create_rag_chain(vectorstore: Chroma):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    template = \"\"\"You are a helpful assistant that answers questions based only on the provided context.\n",
    "If you don't know the answer from the context, say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer in a concise, technical style when appropriate.\n",
    "\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "    # Map: get context docs + original question\n",
    "    rag_inputs = RunnableParallel(\n",
    "        context=retriever,\n",
    "        question=RunnablePassthrough()\n",
    "    )\n",
    "\n",
    "    # Chain: (question) -> {context, question} -> prompt -> llm -> str\n",
    "    rag_chain = rag_inputs | prompt | llm\n",
    "    return rag_chain\n",
    "\n",
    "# 6. Simple chat loop\n",
    "def chat_loop(rag_chain):\n",
    "    print(\"RAG chatbot ready. Type 'exit' to quit.\\n\")\n",
    "    while True:\n",
    "        question = input(\"You: \").strip()\n",
    "        if question.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        response = rag_chain.invoke(question)\n",
    "        # response is a ChatMessage; get content\n",
    "        print(f\"Bot: {response.content}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # If you want to reuse a persisted DB, check if it exists first\n",
    "    if PERSIST_DIR and os.path.exists(PERSIST_DIR):\n",
    "        print(\"Loading existing vector store...\")\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        vectorstore = Chroma(\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=PERSIST_DIR,\n",
    "        )\n",
    "    else:\n",
    "        print(\"Loading documents from URL...\")\n",
    "        docs = load_docs_from_url(SOURCE_URL)\n",
    "\n",
    "        print(\"Splitting documents...\")\n",
    "        chunks = split_docs(docs)\n",
    "\n",
    "        print(\"Building vector store...\")\n",
    "        vectorstore = build_vectorstore(chunks)\n",
    "\n",
    "    print(\"Creating RAG chain...\")\n",
    "    rag_chain = create_rag_chain(vectorstore)\n",
    "\n",
    "    chat_loop(rag_chain)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276c537-258f-4875-a660-68f55d370114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
